{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchmin import Minimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  2., inf,  4.,  5.])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "ar = np.array([1., 2., 3., 4., 5.])\n",
    "\n",
    "ar[2] = np.nan\n",
    "\n",
    "np.nan_to_num(ar, nan=np.inf, copy=False)\n",
    "ar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(507.1351)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# timeit\n",
    "\n",
    "N = 100\n",
    "M = 4\n",
    "v = torch.randn(N)\n",
    "v\n",
    "K = torch.randn(N, N).abs()\n",
    "\n",
    "A = torch.randn(N, M)\n",
    "\n",
    "@torch.jit.script\n",
    "def f1(K,A):\n",
    "    f_hat = K @ A\n",
    "    f_hat_K_tch_inv = torch.linalg.solve(K, f_hat)\n",
    "    return torch.trace(f_hat.T @ f_hat_K_tch_inv)\n",
    "\n",
    "@torch.jit.script\n",
    "def f2(K,A):\n",
    "    f_hat = K @ A\n",
    "    return torch.trace(f_hat.T @ torch.inverse(K) @ f_hat)\n",
    "\n",
    "def f3(K,A):\n",
    "    f_hat = K @ A\n",
    "    f_hat_K_tch_inv = torch.linalg.solve(K, f_hat)\n",
    "    return torch.trace(f_hat.T @ f_hat_K_tch_inv)\n",
    "\n",
    "def f4(K,A):\n",
    "    f_hat = K @ A\n",
    "    return torch.trace(f_hat.T @ torch.inverse(K) @ f_hat)\n",
    "f1(K,A)\n",
    "\n",
    "# %timeit f1(K,A)\n",
    "# %timeit f2(K,A)\n",
    "# %timeit f3(K,A)\n",
    "# %timeit f4(K,A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from stpy.continuous_processes.gauss_procc import GaussianProcess\n",
    "from stpy.helpers.helper import interval\n",
    "\n",
    "\n",
    "# Parameters\n",
    "N = 500\n",
    "n = 256\n",
    "d = 1\n",
    "eps = 0.01\n",
    "s = 1\n",
    "gamma = 0.1\n",
    "\n",
    "# Set random seed\n",
    "torch.manual_seed(1)\n",
    "\n",
    "# Generate random data\n",
    "x = torch.rand(N, d).double() * 2 - 1\n",
    "xtest = torch.from_numpy(interval(n, d, L_infinity_ball=1))\n",
    "\n",
    "# True Gaussian process\n",
    "GP_true = GaussianProcess(gamma=gamma, kernel_name=\"squared_exponential\", d=d)\n",
    "ytest = GP_true.sample(xtest)\n",
    "GP_true.fit_gp(xtest, ytest)\n",
    "y = GP_true.mean(x).clone()\n",
    "\n",
    "# New data points\n",
    "xnew = x[0, :].view(1, 1) + eps\n",
    "ynew = y[0, 0].view(1, 1) + 1\n",
    "\n",
    "# Combined data\n",
    "x2 = torch.vstack([x, xnew])\n",
    "y2 = torch.vstack([y, ynew])\n",
    "\n",
    "# Initialize models\n",
    "gp_cvx = GaussianProcess(gamma=gamma, kernel_name=\"squared_exponential\", d=d, loss='huber', huber_delta=1.5)\n",
    "# gp_torch = GaussianProcess(gamma=gamma, kernel_name=\"squared_exponential\", d=d, loss='huber_torch', huber_delta=1.5)\n",
    "gp_st = GaussianProcess(gamma=gamma, kernel_name=\"squared_exponential\", d=d, loss='studentT', lam=0.005)\n",
    "\n",
    "# gp_st.fit_gp(x2, y2)\n",
    "# from torch.profiler import profile, record_function, ProfilerActivity \n",
    "\n",
    "# # with profile(activities=[ProfilerActivity.CPU], record_shapes=False) as prof:\n",
    "# #     # Fit models\n",
    "# #     gp_st.optimize_params(type=\"bandwidth\", restarts=1, verbose=True, optimizer='pytorch-minimize', scale=1., weight=1., maxiter=1)\n",
    "\n",
    "# # Fit models\n",
    "# # %timeit gp_cvx.fit_gp(x2, y2)\n",
    "# # %timeit gp_torch.fit_gp(x2, y2)\n",
    "\n",
    "# # mean_cvx = gp_cvx.mean(xtest)\n",
    "# # mean_torch = gp_torch.mean(xtest)\n",
    "# mean_st = gp_st.mean(xtest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\queim\\micromambaenv\\envs\\stpy39\\lib\\site-packages\\torch\\jit\\_script.py:1138: UserWarning: Warning: monkeytype is not installed. Please install https://github.com/Instagram/MonkeyType to enable Profile-Directed Typing in TorchScript. Refer to https://github.com/Instagram/MonkeyType/blob/master/README.rst to install MonkeyType. \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1115.9382, dtype=torch.float64)\n",
      "tensor(1115.9382, dtype=torch.float64)\n",
      "5.94 ms ± 500 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "5.34 ms ± 651 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1)\n",
    "K = gp_st.kernel(x2, x2)\n",
    "\n",
    "lam = 0.005\n",
    "\n",
    "class StudModel(torch.nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(StudModel, self).__init__()\n",
    "        self.linear_model = torch.nn.Linear(input_dim, output_dim, bias=False).double()\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.linear_model(x)\n",
    "        mu, v, alpha = torch.chunk(output, 3, dim=-1)\n",
    "        # transform v and alpha to be positive\n",
    "        v = torch.nn.functional.softplus(v) + 1. + 1e-4\n",
    "        alpha = torch.nn.functional.softplus(alpha) + 1e-4\n",
    "        return mu, alpha, v\n",
    "\n",
    "def student_t_loss1(K, y, model):\n",
    "    mu, v, alpha = model(K)\n",
    "    v_alpha = v * alpha\n",
    "    nll = torch.lgamma(0.5*v) + 0.5*torch.log(torch.pi*v_alpha) - torch.lgamma((v+1)*0.5) + ((v+1)*0.5)*torch.log((1 + (y-mu)**2 /v_alpha))\n",
    "    nll = nll.sum()\n",
    "    p = next(model.parameters())\n",
    "    reg = lam * torch.trace(p @ K @ p.T)\n",
    "    return nll + reg\n",
    "\n",
    "\n",
    "model = StudModel(y2.shape[0], 3)\n",
    "model2 = StudModel(y2.shape[0], 3)\n",
    "\n",
    "model2.linear_model.weight.data = model.linear_model.weight.data.clone()\n",
    "\n",
    "model = torch.jit.script(model, example_inputs=[K])\n",
    "\n",
    "\n",
    "\n",
    "optimizer1 = Minimizer(model.parameters(), method=\"l-bfgs\")\n",
    "\n",
    "def closure1():\n",
    "    optimizer1.zero_grad()\n",
    "    loss = student_t_loss1(K, y2, model)\n",
    "    return loss\n",
    "\n",
    "# loss = optimizer.step(closure1)\n",
    "\n",
    "with torch.no_grad():\n",
    "    print(closure1())\n",
    "\n",
    "%timeit closure1()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mean_cvx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[66], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(xtest, \u001b[43mmean_cvx\u001b[49m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcvx\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# plt.plot(xtest, mean_torch, label='torch')\u001b[39;00m\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(x, y, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mo\u001b[39m\u001b[38;5;124m'\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mean_cvx' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "plt.plot(xtest, mean_cvx, label='cvx')\n",
    "# plt.plot(xtest, mean_torch, label='torch')\n",
    "plt.plot(x, y, 'o', label='data')\n",
    "plt.plot(xnew, ynew, 'o', label='new data')\n",
    "\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
